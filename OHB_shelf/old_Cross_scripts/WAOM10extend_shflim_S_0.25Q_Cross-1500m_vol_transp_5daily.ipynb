{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f66ccdc-9591-4da5-8390-f944623a8e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ocean Heat Budget Analyses in the Antarctica continental shelf (WAOM)\n",
    "\n",
    "# Fabio B Dias - 28 June 2023\n",
    "# Description:\n",
    "#     this script obtain and save the 1500m isobath contour variables, which is used for the \n",
    "#     cross-shelf heat transport estimates\n",
    "\n",
    "# read nc output from WAOM 10km run\n",
    "\n",
    "import xarray as xr\n",
    "import pandas as p\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as dates\n",
    "from matplotlib.ticker import NullFormatter\n",
    "from matplotlib.colors import LinearSegmentedColormap   # for custom colormaps\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from netCDF4 import Dataset\n",
    "from netCDF4 import num2date, date2num\n",
    "from matplotlib.ticker import NullFormatter\n",
    "from matplotlib.colors import LinearSegmentedColormap   # for custom colormaps\n",
    "\n",
    "import gsw\n",
    "\n",
    "import pyresample\n",
    "\n",
    "from dask.distributed import Client\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb9013d-1d2e-40b3-8f31-80879e2f5438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(560, 630) (560, 630)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "(560, 630) (560, 630)\n",
      "Vtransform=2\n",
      "73 31\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# load ice draft to create masks\n",
    "di = xr.open_dataset('/g/data3/hh5/tmp/access-om/fbd581/ROMS/OUTPUT/waom10extend_shflim_S_0.25Q/output_20yr_diag/ocean_avg_0001.nc')\n",
    "ice_draft = di.variables[\"zice\"]\n",
    "\n",
    "mask_zice = ma.masked_where(ice_draft < 0, np.ones(ice_draft.shape))\n",
    "mask_outice = ma.masked_where(ice_draft >= 0, np.ones(ice_draft.shape))\n",
    "di.close()\n",
    "\n",
    "dg = xr.open_dataset(\"/g/data3/hh5/tmp/access-om/fbd581/ROMS/waom10_frc/waom10extend_grd.nc\")\n",
    "\n",
    "lat_rho = dg.variables[\"lat_rho\"]\n",
    "lon_rho = dg.variables[\"lon_rho\"]\n",
    "lat_u = dg.variables[\"lat_u\"]\n",
    "lon_u = dg.variables[\"lon_u\"]\n",
    "lat_v = dg.variables[\"lat_v\"]\n",
    "lon_v = dg.variables[\"lon_v\"]\n",
    "pm = dg.variables[\"pm\"]\n",
    "pn = dg.variables[\"pn\"]\n",
    "h = dg.variables[\"h\"]\n",
    "\n",
    "# ds.coords['lat_rho']=lat_rho.transpose() # put lat_rho into ds dataset\n",
    "# ds.coords['lon_rho']=lon_rho.transpose() # put lon_rho into ds dataset\n",
    "\n",
    "area=np.divide(1,pm*pn)\n",
    "\n",
    "## creating the contour, such as a isobath, and extracting the coordinates using matplotlib's Path class\n",
    "# based on https://github.com/COSIMA/cosima-recipes/blob/master/DocumentedExamples/Cross-contour_transport.ipynb\n",
    "\n",
    "h = dg.h.load()\n",
    "\n",
    "h = h*mask_zice\n",
    "\n",
    "# Fill in land with zeros:\n",
    "h = h.fillna(0)\n",
    "\n",
    "contour_depth = 1500.\n",
    "\n",
    "## Choose whether you want your contour on the u or t grid.\n",
    "grid_sel = 't'\n",
    "if grid_sel == 'u':\n",
    "    x_var = lon_u\n",
    "    y_var = lat_u\n",
    "elif grid_sel == 't':\n",
    "    x_var = lon_rho\n",
    "    y_var = lat_rho\n",
    "\n",
    "    fig = plt.figure(figsize = (8, 6))\n",
    "count = 164 # contour 87 for 2000m isobath, 165 for 1500m\n",
    "x_contour = []\n",
    "y_contour = []\n",
    "\n",
    "# Create the contour:\n",
    "sc = plt.contour(h, levels=[contour_depth])\n",
    "for collection in sc.collections:\n",
    "    for path in collection.get_paths():\n",
    "        # print(collection.get_paths())\n",
    "\n",
    "        count += 1\n",
    "        if count ==  212:\n",
    "            # Write down the lat/lon indices\n",
    "            for ii in range(np.size(path.vertices[:,0])):\n",
    "                x_contour.append(int(np.round(path.vertices[ii][0])))\n",
    "                y_contour.append(int(np.round(path.vertices[ii][1])))\n",
    "\n",
    "plt.scatter(x_contour, y_contour, s=5, alpha=0.5, color='tomato');\n",
    "\n",
    "## SHOULD I SMOOTH IT? PROBABLY YES!\n",
    "\n",
    "# Difference between two neighbouring indices\n",
    "diff_x_contour = np.diff(x_contour)\n",
    "diff_y_contour = np.diff(y_contour)\n",
    "\n",
    "# Get a list with the indices of duplicates\n",
    "diff_ind = []\n",
    "for ii in range(len(diff_x_contour)):\n",
    "    if (diff_x_contour[ii]==0) and (diff_y_contour[ii]==0):\n",
    "        diff_ind.append(ii)\n",
    "\n",
    "# Now remove the indices (start from the end so the indices don't shift)\n",
    "for ii in range(len(diff_ind)):\n",
    "    index = diff_ind[::-1][ii]\n",
    "    del x_contour[index]\n",
    "    del y_contour[index]\n",
    "\n",
    "h_contour = np.zeros(len(x_contour))\n",
    "\n",
    "for ii in range(len(h_contour)):\n",
    "    h_contour[ii] = h[y_contour[ii], x_contour[ii]]\n",
    "\n",
    "# Get lat/lon along the contour\n",
    "\n",
    "# Choose whether you want your contour on the u or t grid.\n",
    "grid_sel = 't'\n",
    "\n",
    "if grid_sel == 'u':\n",
    "    x_var = lon_u\n",
    "    y_var = lat_u\n",
    "elif grid_sel == 'v':\n",
    "    x_var = lon_v\n",
    "    y_var = lat_v\n",
    "elif grid_sel == 't':\n",
    "    x_var = lon_rho\n",
    "    y_var = lat_rho\n",
    "\n",
    "lat_along_contour = np.zeros((len(x_contour)))\n",
    "lon_along_contour = np.zeros((len(x_contour)))\n",
    "\n",
    "for ii in range(len(h_contour)):\n",
    "    lon_along_contour[ii] = x_var[y_contour[ii-1],x_contour[ii-1]]\n",
    "    lat_along_contour[ii] = y_var[y_contour[ii-1],x_contour[ii-1]]\n",
    "\n",
    "# Repeat the leftmost point at the end of the array.\n",
    "# (Required for masking contour above and below)\n",
    "\n",
    "lat_along_contour = np.append(lat_along_contour, lat_along_contour[0])\n",
    "lon_along_contour = np.append(lon_along_contour, lon_along_contour[0])\n",
    "\n",
    "# Number of grid points on the contour\n",
    "num_points = len(lat_along_contour)\n",
    "\n",
    "# Now we number the points along the contour\n",
    "contour_mask_numbered = np.zeros_like(lon_along_contour)\n",
    "\n",
    "for ii in range(num_points-1):\n",
    "    lat1 = lat_along_contour[ii]\n",
    "    lat2 = lat_along_contour[ii+1]\n",
    "    lon1 = lon_along_contour[ii]\n",
    "    lon2 = lon_along_contour[ii+1]\n",
    "    contour_mask_numbered[ii] = ii\n",
    "\n",
    "contour_mask = h*0\n",
    "\n",
    "for ii in range(num_points-1):\n",
    "    contour_mask[y_contour[ii], x_contour[ii]] = contour_mask_numbered[ii]+1\n",
    "\n",
    "mask_value = -1000\n",
    "contour_mask_numbered = contour_mask\n",
    "\n",
    "# fill in points to south of contour:\n",
    "contour_masked_above = np.copy(contour_mask_numbered)\n",
    "contour_masked_above[-1, 0] = mask_value\n",
    "\n",
    "#Create mask\n",
    "#Now we create a mask below contour sothat the direction of the contour can be determined\n",
    "\n",
    "#Remark on computational inefficiency:\n",
    "#Note that creating masks with nested for loops is very inefficient. We should probably use boolean masks (just compare the entire array with mask_value), and DataArray.shift() or DataArray.roll() from each of the directions to generate the masks without using loops.\n",
    "#See discussion in: https://github.com/COSIMA/cosima-recipes/issues/179\n",
    "\n",
    "print(contour_masked_above.shape, contour_mask_numbered.shape)\n",
    "print(contour_masked_above[-20:-1, 0])\n",
    "\n",
    "# fill in points to south of contour:\n",
    "contour_masked_above = np.copy(contour_mask_numbered)\n",
    "contour_masked_above[-1, 0] = mask_value\n",
    "\n",
    "# from top left:\n",
    "for ii in range(len(contour_mask[0,:])-1): #x: len(x-axis) - 1\n",
    "    for jj in range(len(contour_mask[:,0]))[::-1][:-1]: #y: len(y-axis)[from end to start, inverse order][from first to (end-1)]\n",
    "        if contour_masked_above[jj, ii] == mask_value: # if north of contour line\n",
    "            if contour_masked_above[jj-1, ii] == 0: # if previous cell in Y-dir is zero (= south of contour line)\n",
    "                contour_masked_above[jj-1, ii] = mask_value # make it -1000\n",
    "            if contour_masked_above[jj, ii+1] == 0: # if next cell in X-dir is zero\n",
    "                contour_masked_above[jj, ii+1] = mask_value # make it -1000\n",
    "\n",
    "#from top right:\n",
    "for ii in range(len(contour_mask[0,:]))[::-1][:-1]:\n",
    "    for jj in range(len(contour_mask[:,0]))[::-1][:-1]:\n",
    "        if contour_masked_above[jj, ii] == mask_value:\n",
    "            if contour_masked_above[jj-1, ii] == 0: # if previous cell in Y-dir is zero\n",
    "                contour_masked_above[jj-1, ii] = mask_value\n",
    "            if contour_masked_above[jj, ii-1] == 0: # if previous cell in X-dir is zero\n",
    "                contour_masked_above[jj, ii-1] = mask_value\n",
    "\n",
    "# from bottom right:\n",
    "for ii in range(len(contour_mask[0,:]))[::-1][:-1]:\n",
    "    for jj in range(len(contour_mask[:,0])-1):\n",
    "        if contour_masked_above[jj, ii] == mask_value:\n",
    "            if contour_masked_above[jj+1, ii] == 0: # if next cell in Y-dir is zero\n",
    "                contour_masked_above[jj+1, ii] = mask_value\n",
    "            if contour_masked_above[jj, ii-1] == 0: # if previous cell in X-dir is zero\n",
    "                contour_masked_above[jj, ii-1] = mask_value\n",
    "\n",
    "#from bottom left:\n",
    "for ii in range(len(contour_mask[0,:])-1):\n",
    "    for jj in range(len(contour_mask[:,0])-1):\n",
    "        if contour_masked_above[jj, ii] == mask_value:\n",
    "            if contour_masked_above[jj+1, ii] == 0: # if next cell in Y-dir is zero\n",
    "                contour_masked_above[jj+1, ii] = mask_value\n",
    "            if contour_masked_above[jj, ii+1] == 0: # if next cell in X-dir is zero\n",
    "                contour_masked_above[jj, ii+1] = mask_value\n",
    "\n",
    "mask_shelf2 = ma.masked_where(contour_masked_above == -1000, np.ones(h.shape))\n",
    "\n",
    "# Direction of cross-contour transport\n",
    "\n",
    "mask_x_transport = np.zeros_like(contour_mask_numbered)\n",
    "mask_y_transport = np.zeros_like(contour_mask_numbered)\n",
    "\n",
    "mask_y_transport_numbered = np.zeros_like(contour_mask_numbered)\n",
    "mask_x_transport_numbered = np.zeros_like(contour_mask_numbered)\n",
    "\n",
    "# make halos: add 2 extra columns with the value of the last/first columns of the original\n",
    "shape = contour_masked_above.shape\n",
    "contour_masked_above_halo = np.zeros((shape[0], shape[1]+2))\n",
    "contour_masked_above_halo[:, 0] = contour_masked_above[:, -1]\n",
    "contour_masked_above_halo[:, 1:-1] = contour_masked_above\n",
    "contour_masked_above_halo[:, -1] = contour_masked_above[:, 0]\n",
    "\n",
    "new_number_count = 1\n",
    "for mask_loc in range(1, int(np.max(contour_mask_numbered))+1):\n",
    "    #if mask_loc%100 == 0:\n",
    "    #    print('mask for x/y transport at point '+str(mask_loc))\n",
    "    index_i = np.where(contour_mask_numbered==mask_loc)[1]\n",
    "    index_j = np.where(contour_mask_numbered==mask_loc)[0]\n",
    "    # if point above is towards Antarctica and point below is away from Antarctica:\n",
    "    # take transport grid point to north of t grid:\n",
    "    if (contour_masked_above[index_j+1, index_i]==0) and (contour_masked_above[index_j-1, index_i]!=0):\n",
    "        mask_y_transport[index_j, index_i] = -1\n",
    "        # important to do\n",
    "        mask_y_transport_numbered[index_j, index_i] = new_number_count\n",
    "        new_number_count += 1\n",
    "    # if point below is towards Antarctica and point above is away from Antarctica:\n",
    "    # take transport grid point to south of t grid:\n",
    "    elif (contour_masked_above[index_j-1, index_i]==0) and (contour_masked_above[index_j+1, index_i]!=0):\n",
    "        mask_y_transport[index_j-1, index_i] = 1\n",
    "        mask_y_transport_numbered[index_j-1, index_i] = new_number_count\n",
    "        new_number_count += 1\n",
    "    # if point to right is towards Antarctica and point to left is away from Antarctica:\n",
    "    # zonal indices increased by 1 due to halos\n",
    "    # take transport grid point on right of t grid:\n",
    "    if (contour_masked_above_halo[index_j, index_i+2]==0) and (contour_masked_above_halo[index_j, index_i]!=0):\n",
    "        mask_x_transport[index_j, index_i] = -1\n",
    "        mask_x_transport_numbered[index_j, index_i] = new_number_count\n",
    "        new_number_count += 1\n",
    "    # if point to left is towards Antarctica and point to right is away from Antarctica:\n",
    "    # take transport grid point on left of t grid:\n",
    "    elif (contour_masked_above_halo[index_j, index_i]==0) and (contour_masked_above_halo[index_j, index_i+2]!=0):\n",
    "        mask_x_transport[index_j, index_i-1] = 1\n",
    "        mask_x_transport_numbered[index_j, index_i-1] = new_number_count\n",
    "        new_number_count += 1\n",
    "\n",
    "# We now have the coordinates of the contours, and whether the x or y transport is needed to calculate cross-contour transport.\n",
    "\n",
    "print(pm.shape, pn.shape)\n",
    "\n",
    "# Now we need to interpolate the mask_x/y_transport to the corresponding lon/lat_u/v grids\n",
    "# so we can multiply by the U/V transport\n",
    "\n",
    "# re-grid from rho to u/v-grids\n",
    "rho_def = pyresample.geometry.SwathDefinition(lons=lon_rho,lats=lat_rho)\n",
    "u_def = pyresample.geometry.SwathDefinition(lons=lon_u,lats=lat_u)\n",
    "v_def = pyresample.geometry.SwathDefinition(lons=lon_v,lats=lat_v)\n",
    "\n",
    "wf = lambda r: 1/r\n",
    "\n",
    "mask_x_transport_Ugrd = pyresample.kd_tree.resample_custom(rho_def,mask_x_transport,u_def,\\\n",
    "                                         radius_of_influence=100000,neighbours=1,weight_funcs=wf)\n",
    "mask_y_transport_Vgrd = pyresample.kd_tree.resample_custom(rho_def,mask_y_transport,v_def,\\\n",
    "                                         radius_of_influence=100000,neighbours=1,weight_funcs=wf)\n",
    "mask_x_transport_numbered_Ugrd = pyresample.kd_tree.resample_custom(rho_def,mask_x_transport_numbered,u_def,\\\n",
    "                                         radius_of_influence=100000,neighbours=1,weight_funcs=wf)\n",
    "mask_y_transport_numbered_Vgrd = pyresample.kd_tree.resample_custom(rho_def,mask_y_transport_numbered,v_def,\\\n",
    "                                         radius_of_influence=100000,neighbours=1,weight_funcs=wf)\n",
    "\n",
    "# Convert contour masks to data arrays, so we can multiply them later.\n",
    "# We need to ensure the lat lon coordinates correspond to the actual data location:\n",
    "#       The y masks are used for ty_trans, so like vhrho this should have dimensions (yu_ocean, xt_ocean).\n",
    "#       The x masks are used for tx_trans, so like uhrho this should have dimensions (yt_ocean, xu_ocean).\n",
    "#       However the actual name will always be simply y_ocean/x_ocean irrespective of the variable\n",
    "#       to make concatenation of transports in both direction and sorting possible.\n",
    "coordinates=dict(one=lon_rho, two=lat_rho)\n",
    "coordinatesU=dict(one=lon_u, two=lat_u)\n",
    "coordinatesV=dict(one=lon_v, two=lat_v)\n",
    "\n",
    "\n",
    "mask_x_transport_Ugrd = xr.DataArray(mask_x_transport_Ugrd, coords = coordinatesU, dims = ['eta_u', 'xi_u'])\n",
    "mask_y_transport_Vgrd = xr.DataArray(mask_y_transport_Vgrd, coords = coordinatesV, dims = ['eta_v', 'xi_v'])\n",
    "mask_x_transport_numbered_Ugrd = xr.DataArray(mask_x_transport_numbered_Ugrd, coords = coordinatesU, dims = ['eta_u', 'xi_u'])\n",
    "mask_y_transport_numbered_Vgrd = xr.DataArray(mask_y_transport_numbered_Vgrd, coords = coordinatesV, dims = ['eta_v', 'xi_v'])\n",
    "\n",
    "# rename dimensions as simply eta/xi\n",
    "mask_x_transport_numbered_Ugrd = mask_x_transport_numbered_Ugrd.rename({'eta_u': 'eta','xi_u': 'xi'})\n",
    "mask_y_transport_numbered_Vgrd = mask_y_transport_numbered_Vgrd.rename({'eta_v': 'eta','xi_v': 'xi'})\n",
    "\n",
    "# Create the contour order data-array. Note that in this procedure the x-grid counts have x-grid\n",
    "#   dimensions and the y-grid counts have y-grid dimensions, but these are implicit, the dimension\n",
    "#   *names* are kept general across the counts, the generic y_ocean, x_ocean, so that concatening works\n",
    "#   but we dont double up with numerous counts for one lat/lon point.\n",
    "\n",
    "# stack contour data into 1d:\n",
    "mask_x_numbered_1d = mask_x_transport_numbered_Ugrd.stack(contour_index = ['eta', 'xi'])\n",
    "mask_x_numbered_1d = mask_x_numbered_1d.where(mask_x_numbered_1d > 0, drop = True)\n",
    "\n",
    "mask_y_numbered_1d = mask_y_transport_numbered_Vgrd.stack(contour_index = ['eta', 'xi'])\n",
    "mask_y_numbered_1d = mask_y_numbered_1d.where(mask_y_numbered_1d > 0, drop = True)\n",
    "\n",
    "contour_ordering = xr.concat((mask_x_numbered_1d, mask_y_numbered_1d), dim = 'contour_index', data_vars=\"all\")\n",
    "contour_ordering = contour_ordering.sortby(contour_ordering)\n",
    "contour_index_array = np.arange(1, len(contour_ordering)+1)\n",
    "\n",
    "# using xr.open_mfdataset\n",
    "\n",
    "vars2drop = [\"ubar\",\"vbar\",\"w\",\"Hsbl\",\"Hbbl\",\"swrad\"]\n",
    "\n",
    "ds = xr.open_mfdataset(paths=\"/g/data3/hh5/tmp/access-om/fbd581/ROMS/OUTPUT/waom10extend_shflim_S_0.25Q/output_20yr_diag/ocean_avg_00*.nc\" , chunks={'eta_rho': '200MB'}, parallel=bool, drop_variables=vars2drop, decode_times=False) # , concat_dim=\"ocean_time\"\n",
    "\n",
    "#- preserving 5-days avgs\n",
    "temp = ds.variables[\"temp\"]\n",
    "salt = ds.variables[\"salt\"]\n",
    "shflux = ds.variables[\"shflux\"]\n",
    "ssflux = ds.variables[\"ssflux\"]\n",
    "m = ds.variables[\"m\"]\n",
    "HvomT = ds.variables[\"Hvom_temp\"]       ## !!! Huon_temp/Hvom_temp were not saved in the original run\n",
    "HuonT = ds.variables[\"Huon_temp\"]       ## now it's running here: /scratch/gi0/fbd581/waom4extend_shflim_S_0.25Q/output_yr10_diag\n",
    "Hvom = ds.variables[\"Hvom\"]\n",
    "Huon = ds.variables[\"Huon\"]\n",
    "\n",
    "ds = ds.set_coords(['Cs_r', 'Cs_w', 'hc', 'h', 'Vtransform'])\n",
    "\n",
    "Zo_rho = (ds.hc * ds.s_rho + ds.Cs_r * ds.h) / (ds.hc + ds.h)\n",
    "z_rho = ds.zeta + (ds.zeta + ds.h) * Zo_rho + ds.zice\n",
    "print(\"Vtransform=2\")\n",
    "Zo_w = (ds.hc * ds.s_w + ds.Cs_w * ds.h) / (ds.hc + ds.h)\n",
    "z_w = ds.zeta + (ds.zeta + ds.h) * Zo_w + ds.zice\n",
    "\n",
    "ds.close()\n",
    "\n",
    "# define a function to extract any 4D var along the contour line\n",
    "\n",
    "def extract_transp_across_contour(var_x, var_y):   # var:4D [time,eta_rho,xi_rho]\n",
    "\n",
    "    zlen = len(temp[0,:,0,0])\n",
    "    tlen = len(temp[:,0,0,0])\n",
    "    print(tlen,zlen)\n",
    "    transp_across_contour = np.empty((tlen,zlen,len(contour_ordering)))\n",
    "\n",
    "    for tt in range(0,tlen): # loop through time\n",
    "        for zz in range(0,zlen): # loop through z-levels\n",
    "            var_x_tmp = var_x[tt,zz,:,:]*mask_x_transport_Ugrd\n",
    "            var_y_tmp = var_y[tt,zz,:,:]*mask_y_transport_Vgrd\n",
    "\n",
    "            # stack transports into 1d and drop any points not on contour:\n",
    "            x_var_1d_tmp = var_x_tmp.stack(contour_index = ['eta', 'xi'])\n",
    "            x_var_1d_tmp = x_var_1d_tmp.where(mask_x_numbered_1d>0, drop = True)\n",
    "            y_var_1d_tmp = var_y_tmp.stack(contour_index = ['eta', 'xi'])\n",
    "            y_var_1d_tmp = y_var_1d_tmp.where(mask_y_numbered_1d>0, drop = True)\n",
    "\n",
    "            # combine all points on contour:\n",
    "            transp_across_contour_tmp = xr.concat((x_var_1d_tmp, y_var_1d_tmp), dim = 'contour_index')\n",
    "            transp_across_contour_tmp = transp_across_contour_tmp.reset_index('contour_index') # added by fabio, otherwise it crashes due to duplicated indices\n",
    "            transp_across_contour_tmp = transp_across_contour_tmp.sortby(contour_ordering)\n",
    "            transp_across_contour_tmp.coords['contour_index'] = contour_index_array\n",
    "            transp_across_contour_tmp = transp_across_contour_tmp.load()\n",
    "\n",
    "            # print(tt, zz, transp_across_contour_tmp.shape)\n",
    "            transp_across_contour[tt,zz,:] = transp_across_contour_tmp\n",
    "            del transp_across_contour_tmp\n",
    "\n",
    "    return transp_across_contour\n",
    "\n",
    "# convert temp to DataArray to extract values along contour:\n",
    "months=np.arange(0,73)*(5/30.41667)\n",
    "\n",
    "# Convert heat transport to data arrays:\n",
    "coordinates3Du = dict(ocean_time=months, s_rho=(['s_rho'], np.arange(0,31)),\n",
    "                    eta_u=(['eta_u'], np.arange(0,560)), xi_u=(['xi_u'], np.arange(0,629)))\n",
    "coordinates3Dv = dict(ocean_time=months, s_rho=(['s_rho'], np.arange(0,31)),\n",
    "                    eta_v=(['eta_v'], np.arange(0,559)), xi_v=(['xi_v'], np.arange(0,630)))\n",
    "\n",
    "# correct Huon/Hvom and HuonT/HvomT using mask_x/y_transport:\n",
    "#  - convection for the northward (+) and southward (-) across contour\n",
    "#Huon_corr = np.empty(Huon.shape)\n",
    "#Hvom_corr = np.empty(Hvom.shape)\n",
    "#\n",
    "#for tt in range(0,73):\n",
    "#    for zz in range(0,31):\n",
    "#        Huon_corr[tt,zz,:] = Huon[tt,zz,:]*mask_x_transport_Ugrd\n",
    "#        Hvom_corr[tt,zz,:] = Hvom[tt,zz,:]*mask_y_transport_Vgrd\n",
    "\n",
    "# - handling x/y transports (Hvom, Huon [m3.s-1]) to calculate heat transport\n",
    "Huon_xr = xr.DataArray(Huon, coords = coordinates3Du, dims = ['ocean_time','s_rho','eta_u', 'xi_u'])\n",
    "Hvom_xr = xr.DataArray(Hvom, coords = coordinates3Dv, dims = ['ocean_time','s_rho','eta_v', 'xi_v'])\n",
    "\n",
    "# rename dimensions as simply eta/xi\n",
    "Huon_xr = Huon_xr.rename({'eta_u': 'eta','xi_u': 'xi'})\n",
    "Hvom_xr = Hvom_xr.rename({'eta_v': 'eta','xi_v': 'xi'})\n",
    "\n",
    "# extract variables:\n",
    "# 1. vol transp\n",
    "vol_trans_across_contour = extract_transp_across_contour(Huon_xr, Hvom_xr)\n",
    "\n",
    "# save to netcdf file:\n",
    "coordinatesC=dict(ocean_time=months, s_rho=(['s_rho'], np.arange(0,31)),\n",
    "                    contour_index_array=(['contour_index_array'], np.arange(0,len(contour_index_array))))\n",
    "\n",
    "heat_trans_across_contour_xr = xr.DataArray(vol_trans_across_contour, coords = coordinatesC, dims = ['ocean_time','s_rho','contour_index_array'])\n",
    "files_path = '/g/data3/hh5/tmp/access-om/fbd581/ROMS/postprocessing/cross_contour_tmp/'\n",
    "heat_trans_across_contour_xr.to_netcdf(files_path + 'WAOM10_vol_trans_1500m_5daily_test', mode='w', format=\"NETCDF4\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbbf2e7-0300-4727-93cb-6ac0ec4c5b01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
